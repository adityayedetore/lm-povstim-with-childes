{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions to read the XML version of the CHILDES corpus adapted from on the [nltk website](http://www.nltk.org/howto/childes.html). \n",
    "\n",
    "XML corpora can be downloaded from the [childes website](https://childes.talkbank.org/data-xml/Eng-NA/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from childes import CHILDESCorpusReader # Edited version of nltk.corpus.reader\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from random import sample\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpora(path_to_corpora, corpora_file_name):\n",
    "    return CHILDESCorpusReader(path_to_corpora, corpora_file_name + \"/.*.xml\")\n",
    "\n",
    "corpora = read_corpora(path_to_corpora=\"./\", corpora_file_name=\"childes-xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes 7 minutes to run on my machine\n",
    "\n",
    "def map_files_to_non_target_child_utterances(corpora):\n",
    "    filtered_corpora = {}\n",
    "    for fileid in corpora.fileids():\n",
    "        participants = get_non_target_child_participants(corpora, fileid)\n",
    "        utterances = get_utterances_filtered_by_participants(corpora, fileid, participants)\n",
    "        if utterances != []:\n",
    "            filtered_corpora[fileid] = utterances\n",
    "    return filtered_corpora\n",
    "\n",
    "def get_non_target_child_participants(corpora, fileid):\n",
    "    non_target_child_participants = []\n",
    "    corpora_participants = corpora.participants(fileid)\n",
    "    for participants in corpora_participants:\n",
    "        for key in participants.keys():\n",
    "            dct = participants[key]\n",
    "            if dct['role'] != \"Target_Child\":\n",
    "                non_target_child_participants.append(dct['id'])\n",
    "    return non_target_child_participants\n",
    "\n",
    "def get_utterances_filtered_by_participants(corpus, fileid, participants):\n",
    "    utterances = corpus.sents(fileid, speaker=participants, replace=True) # replace=True\n",
    "    cleaned_utts = [utt for utt in utterances if utt != []]\n",
    "    return cleaned_utts\n",
    "\n",
    "files_to_utterances = map_files_to_non_target_child_utterances(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_treebank_file(fileid):\n",
    "    for treebank_corpus_name in ['Brown','Soderstrom','Valian','Suppes']:\n",
    "        if treebank_corpus_name in fileid:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def split_treebank(files_to_utterances):\n",
    "    treebank = {file : files_to_utterances[file] for file in files_to_utterances if is_treebank_file(file)}\n",
    "    not_treebank = {file : files_to_utterances[file] for file in files_to_utterances if not is_treebank_file(file)}\n",
    "    return treebank, not_treebank\n",
    "\n",
    "def count_questions(sents):\n",
    "    return len([sent for sent in sents if sent[-1] == '?'])\n",
    "\n",
    "def sort_dict_by_number_of_questions(x):\n",
    "    return {k: v for k, v in sorted(x.items(), key=lambda item: count_questions(item[1]))}\n",
    "\n",
    "def hold_out(files_to_utterances):\n",
    "    files_to_utterances_sorted = sort_dict_by_number_of_questions(files_to_utterances)\n",
    "    included = copy.deepcopy(files_to_utterances_sorted)\n",
    "    excluded = {}\n",
    "    for i,file in enumerate(files_to_utterances_sorted):\n",
    "        if i % 10 == 0:\n",
    "            excluded[file] = included.pop(file)\n",
    "    return included, excluded\n",
    "\n",
    "treebank, not_treebank = split_treebank(files_to_utterances)\n",
    "included_treebank, excluded = hold_out(treebank)\n",
    "included = {**not_treebank, **included_treebank} # Python 3.5 or greater\n",
    "with open('childes-txt/excluded.txt','w') as f:\n",
    "    for s in [utt for utts in excluded.values() for utt in utts]:\n",
    "        f.write(\" \".join(s) +\"\\n\")\n",
    "with open('childes-txt/treebank.txt','w') as f:\n",
    "    for s in [utt for utts in treebank.values() for utt in utts]:\n",
    "        f.write(\" \".join(s) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(files_to_utterances):\n",
    "    files_to_utterances_sorted = sort_dict_by_value_length(files_to_utterances)\n",
    "    utterances = [utts for utts in files_to_utterances_sorted.values()]\n",
    "    train, valid, test = [],[],[]\n",
    "    count = 0\n",
    "    while count < len(utterances) - 100:\n",
    "        sample_indices = sample(range(count, count + 100), 100)\n",
    "        for i in sample_indices[0:90]:\n",
    "            train += utterances[i]\n",
    "        for i in sample_indices[90:95]:\n",
    "            valid += utterances[i]\n",
    "        for i in sample_indices[95:100]:\n",
    "            test += utterances[i]\n",
    "        count += 100\n",
    "    return train, valid, test\n",
    "\n",
    "def sort_dict_by_value_length(x):\n",
    "    return {k: v for k, v in sorted(x.items(), key=lambda item: len(item[1]))}\n",
    "\n",
    "train, valid, test = train_valid_test_split(included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remix_held_out(valid, test, excluded):\n",
    "    excluded_utterances = [utt for utts in excluded.values() for utt in utts]\n",
    "    excluded_size = len(excluded_utterances)\n",
    "    reshuffle_size = int(excluded_size/2)\n",
    "    return valid + train[:reshuffle_size], test[reshuffle_size:] + excluded_utterances\n",
    "\n",
    "valid_remixed, test_remixed = remix_held_out(valid, test, excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(train, valid, test):\n",
    "    with open(\"childes-txt/train.txt\", \"w\") as f:\n",
    "        for s in train:\n",
    "            f.write(\" \".join(s) +\"\\n\")\n",
    "    with open(\"childes-txt/valid.txt\", \"w\") as f:\n",
    "        for s in valid:\n",
    "            f.write(\" \".join(s) +\"\\n\")\n",
    "    with open(\"childes-txt/test.txt\", \"w\") as f:\n",
    "        for s in test:\n",
    "            f.write(\" \".join(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(train, valid_remixed, test_remixed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
